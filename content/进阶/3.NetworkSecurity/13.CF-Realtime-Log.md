---
title: "启用 CloudFront 实时日志并使用 Elasticsearch 分析"
chapter: false
weight: 37
tags:
  - advanced
---


利用 CloudFront 实时日志，您可以实时获取 Distribution 的 HTTP 请求日志，日志在收到请求后的几秒钟内传输。

CloudFront 实时日志将传送到 Amazon Kinesis Data Streams 中您选择的数据流。您可以构建自己的 Kinesis 数据流消费程序，或使用 Amazon Kinesis Data Firehose 将日志数据发送到 Simple Storage Service (Amazon S3)、Amazon Redshift、Amazon Elasticsearch Service (Amazon ES) 或第三方日志处理服务。

本章节将使用 Amazon Elasticsearch Service 作为日志目标，对 CloudFront 实时日志进行可视化分析和展现。

CloudFront 实时日志需要进行以下配置：

 - 实时日志的采样率 – 即希望接收实时日志记录的请求的百分比，如果指定100%，则表示将所有 HTTP 请求日志均实时发送到指定的Kinesis Data Streams

 - 希望在日志记录中接收的特定字段：目前共有40个字段，可以选择只接收特定字段

 - 要接收实时日志的特定缓存行为： CloudFront 实时日志是基于 Distribution 中的每个 Cache Behavior 进行启用
 
 - Kinesis Data Streams：用于接收 CloudFront 实时日志

{{% notice note %}}
CloudFront 实时日志位于 us-east-1 区域，所以需要在 us-east-1 区域创建一个单独的 Elasticsearch 集群，用于分析 CloudFront 实时日志。
{{% /notice  %}}

本实验会使用下面的附件，可以先把这些文件下载到本地。
{{%attachments title="下载链接:" /%}}

1.将当前控制台的语言设置为中文。创建Key pair并下载到本地，用于建立远程登录 Kibana 的 SSH 隧道。

打开EC2 Key pair控制台：https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#KeyPairs:

点击【创建密钥对】按钮

* 在“名称”一栏输入密钥对名称，比如：<你的姓名拼音首字母>_secworkshop_kibana
* 选择密钥格式，如果是用putty连接到EC2，则可以选择ppk，否则选择pem。

点击【创建密钥对】按钮，并将密钥文件保存至电脑。

{{% notice note %}}
如果忘记下载密钥文件，则需要重新创建新的密钥文件并下载。
{{% /notice  %}}

2.点击以下链接，通过 CloudFormation 在 us-east-1 区域快速部署 Elasticsearch 集群

[Launch Template](https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=ES-Sample&templateURL=https://hxh-public.s3-ap-northeast-1.amazonaws.com/Elastsicsearch-Sample.yaml)

 - 堆栈名称：ES-Secworkshop，可以自行修改
 - ESDomainName: 必须为小写英文字符，设置为“secworkshop”。
 - KeyName: 从下拉框里你在第一步中所创建的KeyPair，注意后续需要使用该 Key 建立远程登录 Kibana 的 SSH 隧道
 - KibanaPassword：Kibana Master用户密码，默认指定为P@ssw0rd，可以自行修改
 - KibanaUsername： Kibana Master用户名，默认指定为admin，可以自行修改
 - ResourceName：CloudFormation所创建资源的默认前缀，设置为“secworkshop”

![](/images/3.NetworkSecurity/Cf-realtimelog-Elasticsearch-cloudformation.png)

3.点击【下一步】按钮，在“配置堆栈选项”页面上，保留缺省设置，点击【下一步】按钮。在“审核 ES-Secworkshop”页面，点击【创建堆栈】按钮。

整个堆栈的创建大约需要15分钟。CloudFormation 部署完成后，将会创建以下资源：

 - Elasticsearch VPC, Subnet, Internet Gateway
 - Elasticsearch Cluster: demo
 - Elasticsearch Security Group
 - EC2 Instance: 作为 Proxy 访问 VPC 内部的 ES Kibana
 - EC2 Security Group

请在 CloudFormation 控制台 --> 输出 --> 记录SSLTunnelforKibanaAccess的内容，用于连接 Kibana 的 SSH 隧道建立方式。

{{% notice note %}}
注意需要将 'your-key.pem' 替换成自己的 EC2 Key Pair 文件路径和名称
{{% /notice  %}}
![](/images/3.NetworkSecurity/Cf-realtimelog-CloudFormationOutput.png)

## 创建 Kinesis Data Streams

**注意： Kinesis Data Streams 必须在 us-east-1 区域**

创建 Kinesis Data Streams时，需要先估算分片数量。

{{% notice note %}}
1. 计算（或估算）您的 CloudFront Distribution 每秒钟接收的请求数。
2. 确定单个实时日志记录的典型大小。通常，单个日志记录约为 500 字节。一个包含所有可用字段的大型记录约为 1KB
3. 将每秒钟的请求数（从步骤 1 中）乘以典型的实时日志记录大小（从步骤 2 中），以确定您的实时日志配置每秒可能发送到 Kinesis 数据流的数据量。
4. 使用每秒钟的数据量计算您需要的分片数量。单个分片每秒可处理不超过 1MB 的数据量及 1000 个请求（日志记录）。计算所需的分片数量时，我们建议最多增加 10-25% 作为缓冲。

例如，假设您的分发每秒接收 50000 个请求，且您的实时日志记录的典型大小是 500 字节。这意味着，您的实时日志配置每秒可以生成 25000000 个字节（50000 乘以 500）或者 23.84 MB 的数据量。在此情况下，您需要至少 24 个分片。要增加约 20% 的缓冲，您需要指定 29 个分片。
{{% /notice  %}}

进入 us-east-1 区域的 Kinesis Console，创建 Kinesis Data Streams：https://console.aws.amazon.com/kinesis/home?region=us-east-1#/streams/create

 - 数据流名称: ```cf-realtime-logs```
 - 分区数: 1，即可基本支持 1000 QPS的日志量。
![](/images/3.NetworkSecurity/CF-realtimelog-CreateKinesisDataStreams.png)


## 创建并启用 CloudFront 实时日志

进入 CloudFront Console的实时日志配置界面：https://console.aws.amazon.com/cloudfront/v2/home#/logs/realtime

![](/images/3.NetworkSecurity/Cf-realtimelog-console.png)

点击【Create Configuration】按钮。指定实时日志的配置，包括：

 - Name： cf-realtime-logs
 - 日志采样率： 默认设置为 100
 - 日志字段： 默认全部40个字段
 - Endpoint： 选择接收日志的Kinesis Data Stream，这里选择我们在上一步创建的、名为cf-realtime-logs的Kinesis data stream。
 - Distribution / Cache behaviors： 需要启用实时日志的 Distribution 中的 Cache Behavior，选择所有的behavior。

点击【Create Configuration】按钮，创建实时日志配置。

![](/images/3.NetworkSecurity/Cf-realtimelog-Create-cf-realtimelogs.png)

另外，一个 CloudFront 实时日志的配置，可以关联多个 Distribution 中的多个 Cache behavior。
但是一个 Cache behavior 只能关联一个实时日志的配置。

## 创建 Kinesis Data Firehose 将 CloudFront 实时日志发送到 Amazon Elasticsearch Service

由于 CloudFront 实时日志的格式为 Web access log 格式，所以在使用 Kinesis Data Firehose 将日志注入到 Elasticsearch 前，需要进行格式转换，将类似于的Apache Access Log 的日志格式，添加字段名，转换成 JSON 格式。

原始格式示例如下，每条日志以换行符分割。
```
1609332904.148	116.235.150.132	0.241	200	1223	GET	https	test.huxinhua.top	/	85	SFO5-C3	N5pkTFosgNRXvM5dw9Wn4S7mQrf1Z2DzxwpSaEPBtfbkpboNTc6kkQ==	d2e6e1pvzrqgql.cloudfront.net	0.241	HTTP/1.0	IPv4	ApacheBench/2.3	-	-	-	Miss	-	TLSv1.2	ECDHE-RSA-AES128-GCM-SHA256	Miss	-	-	text/html;%20charset=utf-8	871	-	-	60370	Miss	CN	-	*/*	*	Host:test.huxinhua.top%0AUser-Agent:ApacheBench/2.3%0AAccept:*/*%0A	Host%0AUser-Agent%0AAccept%0A	3
```
而 Kinesis Data Firehose 原生支持使用Lambda，对来自 Source 的格式进行转换，然后加载到目标。

**1. 进入 us-east-1 区域的 Lambda 控制台，创建用于 CloudFront 实时日志格式转换的 Lambda Function。**：https://console.aws.amazon.com/lambda/home?region=us-east-1#/create/function

 - 函数名称: cf-realtime-logs-transformer
 - 运行时: 选择 Python 3.8
 - 其他保留缺省值。点击【创建函数】按钮。
 - 从前面下载的文件中，找到“cf-realtime-logs-transformer.py”，并打开该文件，把其中的代码复制到 lambda_function 中，点击【部署】按钮。
 
![](/images/3.NetworkSecurity/Cf-realtimelog-CreateTransformerLambda.png)

**2. 进入控制台，创建 Kinesis Data Firehose Delivery**：https://console.aws.amazon.com/firehose/home?region=us-east-1#/wizard/nameAndSource

- Step1 
    - 传输流名称： ```cf-realtime-logs```
    - 源： 选择上一步创建的 Kinesis Data Streams，也就是“cf-realtime-logs”
	- 点击【下一步】按钮
- Step2 
    - 数据转换：选择“已启用”单选框，然后指定上一步创建的 Lambda，也就是选中“cf-realtime-logs-transformer”
	- 点击【下一步】按钮
- Step3 
    - 目标： 选择 Amazon Elasticsearch
    - 域： 选择 CloudFormation 创建的 Elasticsearch 集群，比如“secworkshop”
    - 索引： ```cf-realtime-logs```
    - 索引轮换：每天
    - VPC: 选择 CloudFormation 创建的 VPC（默认）
    - 子网: 选择 CloudFormation 创建的 Subnet（默认）
    - 安全组: 选择 CloudFormation 创建的 ES SecurityGroup（默认）
    - S3备份: 选择 仅失败的记录，指定一个 S3 bucket，比如“<你的姓名拼音首字母>_secworkshop”，并指定 Prefix，比如“cfrealtimelogs”
	- 点击【下一步】按钮
- Step4
    - 缓冲区大小: 1MB
    - 缓冲时间间隔: 60 seconds，尽可能快的将日志发送到Elasticsearch
    - 其他选项保留缺省值
	- 点击【下一步】按钮
- Step5
	- 点击【创建传输流】按钮

![](/images/3.NetworkSecurity/Cf-realtimelog-CreateKinesisFirehose1.png)
![](/images/3.NetworkSecurity/Cf-realtimelog-CreateKinesisFirehose2.png)
![](/images/3.NetworkSecurity/Cf-realtimelog-CreateKinesisFirehose3.png)
![](/images/3.NetworkSecurity/Cf-realtimelog-CreateKinesisFirehose4.png)

**3. 登录 Kibana**

为了保证安全性， Elasticsearch 集群部署为 VPC 模式，所以 Kibana 只能从 VPC 内部访问。如果需要从互联网访问 Kibana ，通常有以下几种方式：

 1. 在 VPC 中使用 EC2 搭建一个 Web 代理服务器，例如 Nginx，将从互联网访问 Kibana 的请求代理到 VPC 内的 Elasticsearch，具体步骤[请参考此文档](https://docs.aws.amazon.com/zh_cn/elasticsearch-service/latest/developerguide/es-kibana.html#es-kibana-proxy)。
 2. 使用 Direct Connect / Site-to-Site VPN / ClientVPN 连接到 VPC
 3. 将 VPC 中一台 EC2 作为代理，建立 SSH 隧道，用户通过此 SSH 隧道访问 VPC 内的 Kibana

下面将以第三种方式为例，介绍如何通过 SSH 隧道访问 VPC 内的 Kibana。首先使用 CloudFormation 输出中记录的 SSH 隧道连接方式，建立 SSH 隧道。
如果是mac电脑，则执行下面的命令：
```
## 此 SSH 隧道将本地的 9200 端口代理到远端 Kibana URL 的443端口
HXH:key hxh$ ssh -i us-east1.pem ubuntu@3.92.197.79 -N -L 9200:vpc-demo-lmq3g3rlx2eqmngs3px2ysgr7u.us-east-1.es.amazonaws.com:443
```
如果是windows电脑，则找到本实验最开始下载的文件中的putty工具，并启动该工具。该工具可以无需安装，直接执行。

a.启动putty以后，从CloudFormation 输出中记录的 SSH 隧道连接方式中，拷贝ubuntu@<ip地址>的部分，如下图所示。
![](/images/3.NetworkSecurity/putty1.png)

b.在左边点开“Connection”，再点开“SSH”，再点开“Auth”，在右边的“private key file”一栏，点击【Browse...】按钮，选择第一步中下载的keypair文件。
![](/images/3.NetworkSecurity/putty2.png)

c.在左边点击“Tunnels”，在右边的“Source port”里，输入端口：9200。

然后在Destination一栏输入Kibana的域名，可以从CloudFormation 输出中记录的 SSH 隧道连接方式中找到，比如：vpc-secworkshop-c4agv6xpwokgy7zqq5avlfpgli.us-east-1.es.amazonaws.com:443
![](/images/3.NetworkSecurity/putty3.png)

d.点击【Add】按钮，把source port和destination的内容添加到列表里。
![](/images/3.NetworkSecurity/putty4.png)

e.点击【Open】按钮，建立到跳板机的SSH隧道。

然后在本地浏览器中，打开```https://localhost:9200/_plugin/kibana/```，用输入在之前部署 CloudFormation 时指定的用户名和密码，默认为 ```admin / P@ssw0rd``` .
![](/images/3.NetworkSecurity/Cf-realtimelog-KibanaLogin.png)

**4. 在 Kibana 中创建 Index Template**

默认 CloudFront 实时日志的timestamp字段会被识别成text，所以需要修改Index Mapping，将timestamp字段指定为date格式。

登录Kibana，点开菜单选项，然后选择“Dev Tools” ，复制以下代码创建 Index Template，指定 timestamp 字段格式为 date。

```
PUT _template/cf-realtime-logs-template
{
  "index_patterns": ["cf-realtime-logs-*"],
    "mappings": {
      "properties": {
        "timestamp": {
          "type": "date",
          "format": "yyyy-MM-dd HH:mm:ss"
        }
      }
    }
}
```
![](/images/3.NetworkSecurity/Cf-realtimelog-Kibana-IndexTemplate.png)

**5. 在 Kibana 中配置权限**

首先需要在 Kibana 中 对 Kinesis Data Firehose 的 IAM Role 进行授权，允许 Kinesis Data Firehose 向 Elasticsearch 发送数据。

进入前面创建的Kinesis Data Firehose的控制台：https://console.aws.amazon.com/firehose/home?region=us-east-1#/details/cf-realtime-logs

查看并记录上一步创建的 Kinesis Data Firehose 对应的IAM Role ARN。

![](/images/3.NetworkSecurity/Cf-realtimelog-KinesisRoleARN.png)

登录 Kibana，点开菜单，点击左边的“Security”选项，点击左边的“Roles”选项，在右边找到“all_access” role。
![](/images/3.NetworkSecurity/Cf-realtimelog-kibana-roles.png)

点击“all_access”，并点击“Mapped users”页面，点击【Manage mappings】按钮，将 Firehose 的IAM Role ARN复制到Internal User 或者 Backend Role 均可，然后点击【Map】按钮即可。

![](/images/3.NetworkSecurity/Cf-realtimelog-KibanaMapRole.png)


**6. 在 Kibana 中查看 CloudFront 实时日志**

从电脑发起对 CloudFront Distribution 的访问，产生请求日志。

登录 Kibana，点开菜单，点击左边的“Stack Management”选项，再点击“Index Patterns”选项，点击右边的“Create index pattern”按钮，输入 ```cf-realtime-logs-*```，点击【Next step】按钮。

![](/images/3.NetworkSecurity/Cf-realtimelog-KibanaCreateIndexPattern.png)

然后在“Time field”下拉框里，选择“timestamp”作为时间字段，然后点击【Create index pattern】。

![](/images/3.NetworkSecurity/Cf-realtimelog-KibanaCreateIndexPattern1.png)

在 Kibana 菜单里，选择“Discover”选项，然后可以在右边的窗口里查看访问 CloudFront Distribution 的实时日志

![](/images/3.NetworkSecurity/Cf-realtimelog-KibanaDiscover.png)


**7. 在 Kibana 中对 CloudFront 实时日志进行可视化分析**

从前面下载的文件中，找到模板文件：“cf-dashboard.ndjson”，然后在Kibana菜单上，进入“Stack Management”选项，然后点击“Saved Object”选项，在右边点击“Import”选项，选中“cf-dashboard.ndjson”文件，点击【Import】按钮。

![](/images/3.NetworkSecurity/Cf-realtimelog-KibanaImportDashboard.png)

在Kibana菜单上，进入“Dashboard”选项，在右侧的窗口里找到、并点击名为“CloudFront Dashboard”的dashboard，然后查看 CloudFront 实时日志可视化视图。

![](/images/3.NetworkSecurity/Cf-realtimelog-KibanaDashboard.png)